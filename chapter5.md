# 第5章 优化程序性能

- 编写高效程序要做到以下几点
  - 适当的算法和数据结构
  - 编译器能够有效优化，以转化成高效可执行代码的源代码
  - 并行
    - 见第12章
- 为了使得编译器能够有效优化，需要理解编译器的能力和局限性
  - C语言的特性，如指针运算和强制类型转换，使得编译器很难对它进行优化
  - 需要编译器更容易产生高效可执行代码的方式来编写程序
- 程序优化使得编译器友好，程序员需要做的
  - 消除不必要的工作
    - 有哪些工作可能是不必要的
      - 函数调用
      - 条件测试
      - 内存引用
    - 不依赖于目标机器的任何具体属性
  - 同时执行多条指令
    - 利用了处理器提供的指令级并行能力
- 代码剖析程序（profiler）
  - 测量程序各个部分性能的工具，方便找到效率低的代码段
- 研究汇编代码来理解编译器和产生的代码
  - 一般从内层循环的代码开始
  - 关键路径
    - 循环的反复执行过程中形成的相关数据链
  - 回头修改源代码
- 编译器也在不断更新和改进

## 5.1 优化编译器的能力和局限性

- 大多数编译器，包括GCC，可以指定优化级别来控制优化程度

  - 级别更高，会使用更大量的优化，但是可能增加程序的规模，还可能使标准的调试工具更难进行调试

- 编译器要保证对程序只使用安全的优化，也就是优化前后的版本有一样的行为

- 判断优化是否安全的一个例子——内存别名引用

  ```c
  void twiddle1(long *xp, long *yp) {
      *xp += *yp;
      *xp += *yp;
  }
  
  void twiddle2(long *xp, long *yp) {
      *xp += 2 * yp;
  }
  ```

  - 大多数情况下，两个程序具有相同的行为
  - 函数twiddle2效率更高，
    - twiddle2需要3次内存引用（读\*xp，读\*yp，写\*xp）
    - twiddle1需要6次内存引用（2次读\*xp，2次读\*yp，2次写\*xp）
  - 考虑xp == yp的情况，此时
    - 执行twiddle1后，\*xp是原来的4倍
    - 执行twiddle2后，\*xp是原来的3倍
  - 这种两个指针可能指向同一个内存位置的情况称为内存别名使用
    - 在安全的优化中，编译器必须假设可能发生内存别名引用
    - 这是一个主要的妨碍优化的因素

- 判断优化是否安全的另一个例子——函数调用

  ```c
  long f() {
      return 0;
  }
  
  long func1() {
      return f() +f() + f() + f();
  }
  
  long func2() {
      return 4 * f();
  }
  ```

  - 两个过程计算得到的结果相同

  - 但是如果f代码如下

    ```c
    long counter = 0;
    
    long f() {
        return counter++;
    }
    ```

    - func1返回6，func2返回0
    - 这个函数f有一个副作用——修改了全局状态的一部分，因此改变调用它的次数会改变程序的行为

  - 用内联函数替换优化函数调用

- GCC的优化能力
  - 胜任基本的优化，但是不会作更激进的变化
  - 因此使用GCC的程序员必须写出“适应”GCC的代码

## 5.2 表示程序性能

- 用每元素的周期数（CPE）表示程序性能

  - 处理器的时钟频率通常用周期每秒来表示
  - 从程序员的角度，更倾向于用时钟周期来度量，因为更关心执行一条指令平均要多少周期，而非一个周期有多长

- 一个例子——计算前置和

  - 前置和：每个元素 p<sub>i</sub> 都是前 i 个元素的和

  - 循环展开
    - 为什么循环展开更快？？？见练习题5.11、5.12和 5.19
    - 斜率就是镁元素的周期数（CPE）

## 5.3 程序示例

- 定义一个向量数据结构，如图5-3
  - data_t可以是一些标准数据类型
- 一些操作向量的方法，如图5-4
  - 生成向量
  - 访问向量元素
    - 会判断有没有越界
  - 确定向量长度
- 需要优化的示例代码，图5-5
  - 宏定义，分别实现向量元素的求和和乘积
  - 对图5-5的代码进行一些变化，来查看性能的变化效果，得到有效的变化
  - 表中可以看到，-Og这样的优化，有很明显的性能提升效果

## 5.4 消除循环的低效率

- 图5-6是一个修改后的版本
  - 只求了一次向量长度，保存在局部变量
  - 对某些数据类型有显著的性能提高，其它则影响不大
  - 这种做法被称为代码移动
    - 识别要执行多次，但是结果不会改变的代码，把这段代码移动到前面不会被多次执行的部分
  - 编译器会试着代码移动，但是会假设函数有副作用，因此很多时候做不到，这个时候需要程序员显式进行代码移动

## 5.5 减少过程调用

- 图5-9是一个在图5.6的基础上修改后的版本

  - 不再通过get_vec_element，而是直接访问数组
    - 事实上调用get_vec_element，这个方法也是访问数组，而且还有边界检查，是可以优化的

  - 性能没有明显提升

    - 5.11.2节会继续讨论这个函数

    - 这里采用这种改动，因为实际上这个步骤结合其它步骤，会有显著的性能提升

## 5.6 消除不必要的内存引用

- 图5-10是一个在图5.9的基础上修改后的版本

  - 关键的改动如下

    - 图5-9

      ```c
      for (i = 0; i < length; i++) {
          *dest = *dest OP data[i];
      }
      ```

    - 图5=10

      ```c
      data_t  acc = IDENT;
      
      for (i = 0; i < length; i++) {
          acc = acc OP data[i];
      }
      ```

  - 把原来的内存引用尽量通过寄存器引用来代替
    - 指针肯定是指向内存的，而局部变量存放在寄存器
    - 寄存器读写速度远远快于内存
  - 性能有了显著提高
  - 编译器不会把图5-9的代码转换成图5-10那样在寄存器中累积那个值
    
    - 可能会产生不一样的行为，见书上例子

## 5.7 理解现代处理器

- 之前的优化不依赖于目标机器的任何特性，现在考虑利用处理器微体系结构的优势，也就是处理器用来执行指令的底层系统设计
  - 处理器的实际操作与通过汇编程序所察觉到的大相径庭
    - 处理器实现了指令级并行
    - 效果和顺序执行一致
- 限制程序最大性能的有关微处理器的两种下界
  - 延迟界限
    - 当一系列指令必须严格按照顺序执行时，会遇到延迟界限，因为下一条指令开始前，这一条必须结束
  - 吞吐量界限
    - 刻画了处理器单元的原始计算能力
- 回忆第4章内容，很多类似的

### 5.7.1 整体操作

- 现代微处理器的示意图，图5-11
- 这种处理器是超标量的
  - 每个时钟周期执行多个操作，并且是乱序的
- 整个设计的两个主要部分
  - 指令控制单元（ICU）
    - 从内存中读出指令序列
    - 根据这些指令序列生成一组针对程序数据的基本操作
  - 执行单元（EU）
    - 执行ICU生成的这些操作
- 和按序流水线（第4章）相比，硬件更复杂，但是并行度更好
  - 按序流水线使得每个周期可以执行多条指令，但是还是按照汇编代码的顺序
- 处理器一些工作的描述
  - 取址控制逻辑从指令高速缓存（i-cache）中读取指令
    - i-cache包含最近访问的指令
    - 通常，执行某条指令之前会很早之前就取指，才会有足够时间译码，并且把译码后的操作发送到EU
    - 遇到分支时需要进行分值预测
  - 指令译码逻辑接收实际的程序指令，并把它们转换成一组基本操作（微操作，二进制）
    - 每个微操作都完成一个简单的计算任务，如两数相加，从内存读数据等等
    - 若指令复杂，会被译码成多个微操作
  - EU接收来自指令译码逻辑的操作
    - 每个时钟周期会接收多个操作
    - 这些操作会被分派到一组功能单元里，由它们执行这些操作
      - 读写内存是由加载和存储单元实现的
        - 加载单元从内存读数据到处理器
        - 存储单元从处理器写数据到内存
        - 数据高速缓存
      - 使用投机执行技术对操作求值
        - 最终结果不会存放到程序寄存器或者内存中，直到处理器确定会实际执行这些指令
        - 分之操作被送到EU，来确定分支预测是否正确
          - 如何知道是否正确？？？
      - 算术运算单元
  - 退役单元
    - ICU中，退役单元记录正在进行的处理，并确保它遵守机器级程序的顺序语义
    - 寄存器文件是退役单元的一部分，因为退役单元控制这些寄存器的更新
      - 指令译码时，关于指令的信息被放在队列中，知道发生以下两个结果中的一个
        - 一条指令的操作完成了，并且引起这条指令的分支点都被确认为预测正确，那么这条指令可以退役，并且对寄存器的更新都可以实际执行
        - 引起该指令的某个分支点预测错误，这条指令会被清空，并且丢弃所有计算出来的结果
      - 通过这种方法，预测错误不会改变程序状态
      - 如上描述，所有对程序寄存器的更新只会在指令退役时发生
        - 为了加速指令结果的传递，执行单元之间允许交换此类信息
  - 寄存器重命名
    - ###

### 5.7.2 功能单元的性能

- ###

### 5.7.3 处理器操作的抽象模型

- 数据流
  - 关键路径
- combine4的CPE和延迟界限的关系？？？
  - 除了整数加法的情况，CPE和处理器的延迟界限是一样的
  - 这些函数的性能主要消耗在求和/乘积计算
  - ？？？

#### 5.7.3.1 从机器级代码到数据流图

- 以combine4（图5-10）为例来描述数据流表示法

  - 只关注循环代码

    ```c
    for (i = 0; i < length; i++) {
        acc = acc OP data[i];
    }
    ```

  - 汇编代码

    ```x86arm
    .L25:
    	vmulsd (%rax), %xmm0, %xmm0
    	addq $8, %rdx
    	cmpq %rax, %rdx
    	jne .L25
    ```

    - %rdx存放指向data[i]的指针
    - %rax存放指向data数组末尾的指针
    - %xmm0存放累积值acc

  - 图5-13展示了生成程序数据流的第一步

    - 四条指令扩展成为五步操作
    - 顶部和底部的寄存器方框分别表示开始时和最后的寄存器值
    - 有些操作产生的值不对应于任何寄存器，这些值的传递用操作间的弧线来表示
      - 例如，load操作从内存读出一个值，然后把它直接传递到mul操作
    - 对于循环的代码片段，把访问到的寄存器分为四类
      - 只读，只用做原值，可以作为数据或用来计算内存地址，但是在循环中不会被修改，如%rax，存放数组data的末尾地址
      - 只写，作为数据传送操作的目的，本例中没有这样的寄存器
      - 局部，在循环内部被修改和使用，不过每次迭代之间不相关，如条件码寄存器，cmp操作修改它，然后jne操作使用它，但是这种相关只在本次迭代之内
      - 循环
        - 既作为源值，又作为目的
        - 一次迭代产生的值可能在另一次迭代中用到
        - 如%rdx和%xmm0，对应于程序值data'+ i 和 acc
        - 循环寄存器之间的操作链决定了限制性能的数据相关

  - 图5-14a改进了图5-13，只给出影响程序执行时间的操作和数据相关

    - 顶部是只读寄存器和循环寄存器，底部是只写寄存器和循环寄存器
    - 如果操作符不属于循环寄存器之间的相关链条，就把它们标识成白色
      - 如cmp和jne操作不影响数据流，只要选择分支就会继续循环

  - 图5-14b改进了图5-14a，消除了标识为白色的操作符，而且只保留了循环寄存器

    - 从图中看到，每次迭代之间有两个数据相关
      - 存储在%xmm0的acc，每次迭代之间有相关性，每次迭代中，把acc的旧值乘以一个由load操作得到的数，得到acc的新值
      - 索引i，每次迭代之间有相关性，每次迭代中，i的旧值用来计算load操作的地址，然后add操作也会增加i的值
    - 因此有两条数据相关链，分别对应于mul操作对acc的修改和add操作对data+i的修改
      - 延迟长的会成为关键路径，浮点乘法延迟为5个周期，整数加法延迟为1个周期，因此左边的链会成为关键路径，制约程序性能
    - 这说明了为什么combine4的CPE为5个周期

#### 5.7.3.2 其它性能因素

- 数据流中的关键路径，提供的只是程序需要周期数的下界
  - 整数加法的情况，combine4的CPE为1.27，但是关键路径给出的CPE是1
- 有其它因素影响性能

## 5.8 循环展开

- 循环展开，通过增加每次迭代计算的元素的数量，减少迭代次数
- 例子见图5-16
  - CPE为1.00，性能的确有所提高
- 数据流见图5-19和图5-20
  - 关键路径上依然有n个mul操作
- 编译器会执行循环展开
  - 优化等级设为3或者更高

## 5.9 提高并行性

- 提高并行性的硬件设计基础
  - 每个算术单元都是流水线化的
    - 注意，现代处理器中，不仅仅是处理器实现了流水线化，每个功能单元也都各自实现了流水线化
  - 因此，功能单元可以每个周期开始一个新操作
  - 现行的代码中，每个功能单元要L个周期才开始新操作
    - 因为累积值放在一个变量acc中
    - 在前面对acc的计算完成前，不能计算acc的新值
  - 现在要打破这种顺序相关，来提高性能

### 5.9.1 多个累积变量

- 图5-21是一个2*2循环展开的例子
  - 两次循环展开
  - 两路并行，索引为奇数和偶数的元素分别累积在acc0和acc1中
  - 性能上得到了改进，打破了延迟界限设下的限制
- 图5-22是combine6的内循环代码的图形化表示
- 图5-23和图5-24是数据流图
  - 每条关键路径只包含n/2个操作
  - 因此乘法操作的CPE大约为 5/2 = 2.5
  - 整数加因为有太多循环开销，无法达到理论界限0.5
- 图5-25显示了当循环展开k次，并且并行累积k个值的时候，CPE随k的变化曲线
  - 当k足够大时，CPE不断逼近吞吐量界限
- 优化编译器可能做的工作
  - 把combine4的代码首先转换成combine5的二路循环展开
  - 通过引入并行性，将之转换成combine6的版本
  - 由于四舍五入或溢出，combine5和combine6可能产生不同的结果
    - 例如，索引值为偶数的元素绝对值非常大，索引值为奇数的元素索引值接近0
    - 如果直接连乘，可能不会溢出
    - 如果索引值为偶数或奇数的连乘，可能上溢或下溢

### 5.9.2 重新结合变换

- 图5-26给出combine7

  - 和图5-16的combine5唯一的区别就是，内循环中元素合并的方式

    ```c
    acc = (acc OP data[i]) OP data[i + 1];
    acc = acc OP (data[i] OP data[i + 1]);
    ```

  - 这种括号放置的变化，称为重新结合变换，变换后的循环展开形式，称为"2 * 1a"循环展开

  - 性能比较

    - 整数加的性能和 combine5的k*1展开相同
    - 其它三种情况和 combine6的k*k展开相同

- ###

## 5.10 优化合并代码的结果小结

###

##  5.11 一些限制因素

- 之前已经讨论了一些对性能的限制因素
  - 关键路径指明的下界
  - 吞吐量界限
- 本届会考虑其他一些制约因素

### 5.11.1 寄存器溢出

- 并行度太高，临时变量太多，可能会导致用完程序寄存器，只能把某些临时变量放到内存（栈帧）

### 5.11.2 分值预测和预测错误处罚

###

## 5.12 理解内存性能

- 目前为止，我们的代码都只是访问相对比较少量的内存
- 现代处理器包含高速缓存存储器，对这样小批量的存储提供快速访问
- 本节会进一步研究加载和存储操作的性能
  - 如图5-11所示，现代处理器有专门的功能单元来执行加载和存储操作
    - 这些单元内部有缓冲区来保存未完成的内存操作请求
    - 为什么需要缓冲区？？？
  - 第6章会更详细探讨高速缓存如何工作，以及如何写出高速缓存友好的代码

### 5.12.1 加载的性能

- 包含加载操作的程序的性能，既依赖于流水线的能力，也依赖于加载单元的延迟
  - 上述几个例子中，CPE从没有到过0.5以下（吞吐量界限）
  - 因为加载单元有两个，每个周期只能启动一条加载操作
- 到目前为止，还没有出现加载操作的延迟产生的影响，之前的例子中，加载操作的地址只依赖于索引i
- 现在看一个例子图5-31，加载操作的结果决定下一条操作的地址
  - movq指令是循环的瓶颈
  - ？？？

### 5.12.2 存储的性能

- ###

## 5.13 应用：性能提高技术

- ###

## 5.14 确认和消除性能瓶颈

- ###