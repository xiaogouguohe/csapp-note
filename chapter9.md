# 第9章 虚拟内存

- 系统中的进程之间共享CPU和主存，这会引发一些问题
  - 如果太多进程需要太多内存，内存会不够
  - 一个进程可能不小心写入另一个进程的内存
- 为了更有效管理内存，解决者希望问题，提出了虚拟内存的概念
  - 将主存看成磁盘的高速缓存
  - 每个进程的地址空间都是一致的，从而简化内存管理
  - 保护每个进程的地址空间不被其它进程破坏
- 本章对虚拟内存的讨论分为两个角度
  - 前一部分描述虚拟内存如何工作
  - 后一部分描述应用程序如何使用和管理虚拟内存
    - 显式的内存映射
    - malloc

## 9.1 物理和虚拟寻址

- 物理寻址，图9-1
  - CPU访问内存的最自然的方式，直接把物理地址通过内存总线传递给主存
  - 早期PC使用物理寻址，现在的为嵌入式控制器等等仍使用这种方式
- 虚拟寻址，图9-2
  - 虚拟地址经过地址翻译得到物理地址
  - CPU芯片上的内存管理单元（MMU）实现地址翻译
  - MMU通过主存中的查询表来动态翻译虚拟地址

## 9.2 地址空间

- 线性地址空间
  - 大小为N = 2<sup>n</sup>
  - 现代系统通常n为32或64
- 物理地址空间

## 9.3 虚拟内存作为缓存的工具

- 把主存视为磁盘的缓存
  - 事实上，无论用户是通过虚拟地址寻址，还是这个系统根本就没有虚拟地址这个概念，都不影响“主存是磁盘的内存”这个说法
- 虚拟页和物理页
  - 分别由虚拟内存和物理内存被分割得到
  - 大小都为P = 2<sup>p</sup>
- 任意时刻，虚拟页面的集合分为三个不相交的子集
  - 未分配的
  - 缓存的
  - 未缓存的

### 9.3.1 DRAM缓存的组织结构

- 一些术语
  - SRAM缓存表示位于CPU和主存之间的高速缓存
  - DRAM缓存表示虚拟内存系统的缓存，它在主存中缓存虚拟页
- DRAM缓存不命中比SRAM缓存不命中的代价要大很多，这导致了一些设计上的特性
  - 虚拟页往往很大
  - DRAM缓存是全相联的，即任何虚拟页都可以放置在任何物理页中
  - 不命中的替换策略要仔细考虑
  - 用写回而非直写
    - 因为访问磁盘的时间长，直写每次都要写磁盘，写回是被替换时再写磁盘

### 9.3.2 页表

- 同任何缓存一样，当访问一个虚拟地址的时候，需要找到这个地址所在的虚拟页有没有缓存在存储的物理页当中，如果有，是缓存在哪一个物理页
- 通过页表来实现虚拟页映射到物理页
  - 每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表
  - 页表常驻内存
- 页表结构，见9.6，图9-12
- 这里是假设系统先进行地址翻译，再去各级存储中根据物理地址进行访问，而且在内存上层的存储都没有命中，现在已经到了内存级别了

### 9.3.3 页命中

- CPU硬件执行的步骤见图9-13a

  1. 处理器生成一个虚拟地址，传给内存管理单元

  2. 内存管理单元生成对应的页表项地址，并从存储中读到表项
     - 根据页表基址寄存器的页表起始地址和虚拟页号来获得对应的页表项地址
     - 页表是在内存的

  3. 存储向内存管理单元返回页表项

  4. 内存管理单元根据页表项构造物理地址，传给存储
     - 前面4步就是图9-12中地址翻译的过程
     - 先翻译地址，再访问各级存储

  5. 存储返回请求的数据字给处理器

### 9.3.4 缺页

- 页面命中完全由硬件处理，而处理缺页要求硬件和操作系统内核协作完成，如图9-13b

  1. 1~3步和页命中的处理相同

  4. 页表项的有效位为0，因此内存管理单元触发异常，把CPU的控制传递到操作系统内核中的缺页异常处理程序
  5. 缺页处理程序确定物理内存中的牺牲页（替换策略），如果这个页面被修改了，需要更新到磁盘
  6. 缺页处理程序根据物理地址访问磁盘，调入新的页面，并更新内存中页表的页表项
  7. 缺页处理程序返回到原来的进程，再次执行导致缺页的指令，此时就是页命中的处理过程

- 一些对本书排版的一些负面评价

  - 9.3节的第一句话容易引起误解
    - 好像虚拟地址空间对应的是磁盘上的空间，因此访问磁盘需要通过虚拟地址访问；事实上访问磁盘是通过物理地址访问的，所以忽略9.3节开头那句话
    - 因此，系统能使用的物理空间（主存，磁盘等）大小为2<sup>m</sup>而非2<sup>n</sup>
  - 9.3节的标题“虚拟内存作为缓存的工具”似乎也不太妥当
    - 事实上不管这个系统有没有引入虚拟内存这个概念，主存都是磁盘的缓存，虚拟内存的引入只是导致多了地址翻译这一步骤
    - 这一节应该说是，在引入了虚拟内存的情况下，主存作为磁盘的缓存，应当有哪些需要处理的（例如地址翻译等等）

### 9.3.5 分配页面

- 以malloc为例，当操作系统分配一个新的虚拟内存页时，会在磁盘上创建空间，并更新内存中的页表项，使这个表项指向磁盘上这个新创建的页面

## 9.4 虚拟内存作为内存管理的工具

- 在上一节看到了虚拟内存如何提供一种机制，利用DRAM缓存来自更大的虚拟地址空间的页面
  - 第6章提到的存储都是同样的地址空间
- 图9-9展示了虚拟内存如何为进程提供独立的地址空间
  - 每个进程都有一个独立的页表
  - 不同进程的页表项可能指向同一个物理页

- 虚拟内存这样的设计思想，实现了以下的简化
  - 简化链接
    - 独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不用管代码和数据实际存放的物理内存位置
  - 简化加载
    - 加载可执行文件的时候，不会真正把可执行文件从磁盘复制到内存中，而是为可执行文件分配虚拟页，并且在相关的页表项中设置标记位为0，等到被引用的时候再进行缺页处理
    - 将一组连续的虚拟页映射到任意一个文件的任意位置的表示法称作内存映射（9.8）
  - 简化共享
    - 每个进程有自己私有的代码、数据、堆以及栈区域，不和其它进程共享
    - 在一些情况下，还是需要进程共享代码和数据
      - 每个进程必须调用相同的操作系统内核代码
      - 每个C程序都会调用C标准库的程序，如printf
      - 操作系统将不同进程中适当的虚拟页面映射到相同的物理页面，并安排多个进程共享这部分代码
  - 简化内存分配
    - 可以分配k个连续的虚拟内存页面，但映射到物理内存的可以是k个分散的物理页面

## 9.5 虚拟内存作为内存保护的工具

- 计算机系统应当控制进程对内存系统的访问

  - 不允许用户进程修改它的只读代码段
  - 不逊于它访问内核中的代码和数据结构
  - 不允许它访问其它进程的私有内存

  - 不允许它修改与其它进程共享的虚拟页面，除非所有共享者都允许它这么做

- 通过在页表项添加一些许可位，来控制对一个虚拟页面的访问

- 如果违反许可条件，CPU会触发一个保护机制，将控制传递给内核中的异常处理程序，并报错段错误

## 9.6 地址翻译

- 本节讨论如何把一个虚拟地址翻译成物理地址
- 图9-11列出了地址翻译要用到的一些符号
- 图9-12展示了MMU如何应用页表来实现这种映射
  - 在这个系统中，虚拟地址为n位，物理地址为m位
    - 虚拟地址分为p位的虚拟页偏移量和n-p位的虚拟页号
    - 物理地址分为p位的物理页偏移量和m-p位的物理页号
  - 页表结构
    - 页表项分为1位的有效位和m-p位的物理页号
    - 页表基址寄存器保存了页表的起始地址，物理还是虚拟？？？
    - 页表项的有效位表示这个页面在不在存储器中（缺页）
  - 根据VPN来选择页表项
    - 例如，虚拟页号为1时选择页表项1
  - 物理页号串联上物理页偏移量就是物理地址
    - 虚拟页偏移量和物理页偏移量是一样的

### 9.6.1 结合高速缓存和虚拟内存

- 大多数系统是先进行地址翻译，再在各级缓存进行寻址的

### 9.6.2 利用TLB加速地址翻译

- 每次CPU产生一个虚拟地址，MMU就要查阅一个PTE，以便将虚拟地址翻译为物理地址，但是经常插内存开销较大，用TLB（翻译后备缓冲器）缓存页表项
  - TLB在MMU中
  - 寻址方式是虚拟寻址（地址还没有翻译）
  - TLB的行结构见图9-15的VPN
    - 虚拟页号分成索引和标记，分别进行组选择和行匹配
    - 缓存的块是一个页表项
- 图9-16展示了TLB命中和不命中的操作

### 9.6.3 多级页表

- 一级页表存在的问题
  - 一个系统有32位的地址空间，4KB的页面和4B的页表项，那么页表的大小为4MB
    - 页表项需要2<sup>32</sup> / 4K = 1M条
    - 页表大小为1M * 4B = 4MB
  - 也就是说，内存必须始终保存4MB的页表

- 通过多级页表，压缩页表的大小
  - 具体的例子见9.7

### 9.6.4 综合：端到端的地址翻译

- 一个具体的地址翻译的例子
- ###

## 9.7 案例研究：Intel Core i7/Linux内存系统

- 图9-21给出了Core i7内存系统的重要部分
  - 处理器封装包括
    - 四个核
    - 一个所有核共享的L3高速缓存
    - 一个所有核共享的DDR3内存控制器
  - 每个核包括
    - 一个层级结构的TLB
    - 一个层次结构的数据和指令高速缓存
    - 一组快速的点到点链路
      - 为了让一个核与其它核和外部的I/O桥直接通信
  - TLB的一些特性
    - 虚拟寻址
    - 四路相联
  - 高速缓存的一些特性
    - 物理寻址
    - 块大小为64B
    - L1和L2是8路相联的
    - L3是16路相联的
  - 页大小
    - 4KB

### 9.7.1 Core i7 地址翻译

- 图9-22总结了完整的Core i7 地址翻译过程

  - 整个过程从CPU产生虚拟地址的时刻，一直到来自内存的数据字到达CPU
  - Core i7 采用四级页表层次结构，每个进程有自己的私有页表层次结构
  - 虚拟地址为48位
    - 36位的虚拟页号和12位的页内偏移
    - 在页表层次结构中，虚拟页号被分为4部分，每部分9位
  - 物理地址为52位

  - ###

- 图9-23给出了前三级页表项的格式
  - 64位的页表项
  - 40位的下一级页表的物理起始地址
    - 要求页表4KB对齐，因此40位就足够了，找下一级页表的物理起始地址的时候自动往后面补12个0
  - 一些标志位
- 图9-24给出了第四级页表项的格式
  - ###
- 图9-25给出了Core i7 MMU如何使用四级页表层次结构进行地址翻译
  - ###

### 9.7.2 Linux虚拟内存系统

- 本小节介绍linux如何组织虚拟内存，如何处理缺页
- Linux为每个进程维护了一个单独的虚拟地址空间，如图9-26
  - 在了解了地址翻译后，填入有关内核虚拟内存的细节
  - 内核虚拟内存在用户栈之上
  - 内核虚拟内存分为
    - 内核代码和数据
    - 物理内存
      - 以上两个都是进程共享的
      - 这一部分的虚拟内存被映射到所有进程共享的物理页面，如每个进程共享内核的代码和全局数据结构
      - Linux把这部分连续的虚拟内存映射到连续的物理内存
    - 与进程相关的数据结构
      - 页表
      - task和mm结构
      - 内核栈

#### 9.7.2.1 Linux虚拟内存区域

- Linux把虚拟内存组织成一些区域（段）的集合
  - 一个区域就是已分配的虚拟内存的连续片
- 代码段、数据段、堆、共享库段、用户栈都是不同的区域
  - 也就是说，图9-26当中的各个区域之间是可以有间隙的
- 每个存在的虚拟页都保存在某个区域中，不存在不属于任何一个区域的虚拟页
  - 内核不用记录不存在的虚拟页，这样的页也不占用内存、磁盘或内核本身等资源
- 图9-27展示了记录一个进程中虚拟内存区域的内和数据结构
  - 内核为系统中的每个进程维护一个单独的任务结构task_struct，它包含或指向内核运行该进程的所有信息
    - PID
    - 指向用户栈的指针
    - 可执行目标文件的名字
    - 程序计数器
  - task_struct的一个成员指向mm_struct，它描述了虚拟内存当前的状态
    - pgd指向第一级页表的起始地址
    - mmap指向区域结构vm_area_structs的一个链表
  - 区域结构的一些字段
    - vm_start：指向区域起始处
    - vm_end：指向区域结束处
    - vm_prot：描述这个区域包含的所有页的读写权限
    - vm_flags：描述这个区域的页面是否与其它进程共享，以及其它一些信息
    - vm_next：指向下一个链表节点

#### 9.7.2.2 Linux缺页异常处理

- 假设MMU在试图翻译虚拟地址A的时候，触发缺页，这个异常导致控制转移到内核的缺页处理程序，程序会执行以下步骤

  - 判断地址A是否合法

    - 是否在某个区域内
    - 搜索区域结构的链表mmap，比较vm_start和vm_end
    - 因为进程可以创建任意数量的新虚拟内存区域，导致顺序搜索耗时大，因此把链表构建成一棵树
      - 《深入理解Nginx》9.6.1中，epitem的实现也是这样的，通过双向链表和红黑树

  - 试图进行的内存访问是否合法

    - 是否有读写对应的权限

    - 尝试写只读页面，或者用户模式中的进程读内核虚拟内存，都是不合法的

  - 内存操作合法，进行缺页处理

    - 选择牺牲页面
    - 通过物理地址从物理内存中读取到要新页并换入
    - 缺页处理程序返回，CPU重新启动引起缺页的指令，这次就可以成功翻译了

## 9.8 内存映射

- Linux通过将一个虚拟内存区域与磁盘上的一个对象关联起来，以初始化这个虚拟内存区域的内容，这个过程称为内存映射
- 虚拟内存区域可以映射到两种类型的对象
  - Linux文件系统中的普通文件
    - 一个区域可以映射到一个普通磁盘文件的连续部分
    - 文件去被分成页大小的篇，每片包含一个虚拟页面的初始内容
    - 因为按需进行页面调度，所以这些虚拟页面开始的时候没有进入内存，直到CPU第一次引用页面（发射虚拟地址，落在某个页面范围之内）
    - 如果区域比文件区要大，就用零填充这个区域的剩下部分
  - 匿名文件
    - 匿名文件是由内核创建的，包含的全是二进制零
    - 页面调度和之前提到的一样，只不过是用二进制零来覆盖牺牲页面
      - 唱片和内存之间并没有实际的数据传送，直接用二进制零覆盖
    - 这种映射有什么应用场景？？？
- 一旦虚拟页面被初始化，它就在一个由内核维护的专门的交换文件之间换来换去
  - 为什么需要交换文件，不是都存放在磁盘上吗？？？

### 9.8.1 再看共享对象

- 共享对象（贡献库）见7.10和7.11
  - 很多代码都有同样的只读代码区域
  - 为了节省空间
- 一个对象可以被映射到虚拟内存的一个区域，要么作为共享对象，要么作为私有对象
- 图9-29展示了一个共享对象的映射
  - 进程1映射了共享对象之后，见图9-29a
  - 进程2将同一个共享对象映射到它的地址空间
    - 不一定要和进程1在相同的虚拟地址
    - 因为每个对象都有唯一的文件名，内核可以迅速判定出，进程1已经映射了这个对象，并且在物理内存中已经存在它的副本，因此进程2的页表条目也指向了这个物理页面
- 写时复制
  - 两个进程都映射了私有的写时复制对象之后，和共享对象类似，如图9-30a
    - 该区域的对应的页表条目都被标记为只读
  - 进程2写了私有区域的一个页之后，触发保护故障，在物理内存中创建这个页面的一个新副本，更新页表条目，回复页面的可写权限
  - 故障处理程序返回时，CPU重新执行写操作，正常执行

### 9.8.2 再看fork函数

- 本小节介绍fork函数如何创建一个带有自己独立虚拟地址空间的新进程
- fork函数被当前进程调用时
  - 为新进程创建各种数据结构，并分配PID
    - 这些通常是每个进程独有的，因此需要额外的虚拟地址空间
  - 创建当前进程的mm_struct、区域结构和页表的原样副本
    - 写时复制
- fork在新进程中返回时，子进程的虚拟内存刚好和父进程调用fork时的虚拟内存相同

### 9.8.3 再看execve函数

- 假设当前进程中的程序执行了如下调用

  ```c
  execve("a.out", NULL, NULL);
  ```

  加载并运行a.out需要以下几个步骤

  - 删除已经存在的用户区域，即当前进程虚拟地址的用户部分中的区域结构
  - 映射私有区域
  - 映射共享区域
    - 如果a.out程序与共享对象链接，如标准库libc.so，那么这些对象是动态链接到这个程序的，然后再映射到用户虚拟地址空间的共享区域内
  - 设置程序计数器，使之指向代码区域的入口点

- 下次调度这个进程时，从程序计数器指向的入口点开始执行

### 9.8.4 使用mmap函数的用户级内存映射

- mmap函数创建新的虚拟内存区域，并将对象映射到这些区域中

  ```c
  #include <unistd.h>
  #include <sys/mman.h>
  
  void *mmap(void *start, size_t length, int port, int flags, int fd, off_t offset);
  ```

- 图9-32描述了mmap参数的意义

  - mmap函数要求内核创建一个新的虚拟内存区域，这个区域从地址start开始
    - 通常被定义为NULL，怎么使用？？？
  - 将文件描述符fd指定的对象的一个连续的片映射到这个新的区域
  - 这个连续片的大小为length字节
  - 这个连续片从偏移量为offset字节的地方开始
    - 总是假设为NULL？？？
  - prot包含了描述新映射的虚拟内存区域的访问权限位（即响应区域结构中的vm_prot位）
  - 参数flags有描述被映射对象类型的位组成
    - MAP_ANON表明被映射的对象是否为匿名对象（9.8匿名文件）

- mummap函数删除虚拟内存的区域

  ```c
  #include <unistd.h>
  #include <sys/mman.h>
  
  int munmap(void *start, size_t length);
  ```

  - 删除从虚拟地址start开始，由接下来length字节组成的区域

## 9.9 动态内存分配

- 虽然可以使用mmap和munmap函数来创建和删除虚拟内存区域，但是用动态内存分配器更方便，也更好移植
- 动态内存分配器维护着一个进程的虚拟内存区域，称为堆
  - 堆是一个请求二进制零的区域，紧跟在未初始化的数据区域后开始，向上增长
  - 对于每个进程，内核维护着一个变量brk，它指向堆顶
- 分配器将堆视为一组大小不同的块的集合来维护
  - 每个块是一个连续的虚拟内存片
  - 这些片要么已分配，要么空闲
    - 已分配的块显式地保留，供应用程序使用
    - 空闲块保持空闲，直到它显式地被应用所分配
    - 已分配的块保持已分配状态，直到被释放，这种释放可能是应用程序显示执行或内存分配器自身隐式执行
- 分配器的两种基本风格
  - 两种风格都要求应用程序显式分配块
    - 它们的不同之处在于由哪个实体负责释放已分配的块
  - 显示分配器
    - 要求应用显式地释放已分配的块
    - C的malloc和free，C++的new和delete
  - 隐式分配器
    - 要求分配器检测已分配块何时不再被应用程序所使用，再释放这个块
    - 自动释放未使用的已分配块的过程叫做垃圾收集，隐式分配器也叫垃圾收集器
    - Java依赖垃圾收集来释放已分配的块

- 本节剩下的部分讨论显式分配器的设计和实现，9.10讨论隐式分配器
  - 集中讨论管理堆的分配器
  - 实际上，内存分配是一个普遍的概念，可以出现在各种上下文中

### 9.9.1 malloc和free函数

- malloc从堆中分配块

  ```c
  #include <stdlib.h>
  
  void *malloc(size_t size);
  ```

  - 返回一个指针，指向大小为至少size字节的内存块
    - 会对齐
    - 在32位模式中，返回的块的大小总是8的倍数，64位模式中，则总是16的倍数
  - 如果malloc遇到问题（如请求的内存块比可用的虚拟内存还要大），就返回NULL，并返回errno，记录在哪？？？
  - malloc不初始化它返回的内存，如果需要分配并初始化，可以使用calloc
  - 改变一个以前已分配块的大小，可以使用realloc函数
  
- sbrk函数

  ```c
  #include <stdlib.h>
  
  void *sbrk(intptr_t incr);
  ```

  - 通过将内核的brk指针增加incr来扩展和收缩堆
  - 如果成果，返回brk的旧值，否则返回-1，并把errno设置为ENOMEM

- free函数来释放分配的块

  ```c
  #include <stdlib.h>
  
  void free(void ptr);
  ```

  - ptr必须只指向一个从malloc、calloc或realloc获得的已分配块的起始位置，否则free的行为就是未定义的
  - 函数不返回任何值，所以free不会告诉应用出现了错误（9.11）

- 图9-34展示了malloc和free如何管理一个C程序的16字

  - 图9-34d，指针p2执行了被释放得空块，这个时候不能再使用p2，直到应用调用重新初始化

### 9.9.2 为什么要使用动态内存分配

- 硬编码大小来分配数组，无法根据实际使用需要调整数组长度

### 9.9.3 分配器的要求和目标

- 显示分配器必须在一些相当严格的约束条件下工作
  - 处理任意请求序列
    - 一个应用的分配和释放请求可能组成任意的序列
    - 分配器不能假设分配和释放请求的顺序，例如不能假设所有的分配请求都有相匹配的释放请求
  - 立即响应请求
    - 分配器必须立即响应分配请求
    - 因此，不允许分配器为了提高性能，重新排列或缓冲请求
  - 只使用堆
  - 对齐块
    - 分配器必须对齐块，使得它们可以保存任何类型的数据对象
  - 不修改已分配的块
    - 只能操作空闲块
- 在上述限制条件下，尽量让分配器吞吐率最大化和内存使用率最大化，但是这两个性能目标通常相互冲突
  - 最大化吞吐率
  - 最大化内存利用率
    - 虚拟内存的全部数量是受磁盘上交换空间的数量限制的？？？
- 通过峰值利用率来描述一个分配器使用堆的效率
  - 如果应用程序请求p字节的块没那么得到的已分配块的有效载荷是p字节
    - 已分配块的大小大于等于有效载荷

### 9.9.4 碎片

- 造成堆利用率很低的主要原因是碎片，即虽然有未使用的内存，但不能用来满足分配请求
- 两种形式的碎片
  - 内部碎片
    - 已分配块比有效载荷大的时候发生
    - 有很多原因导致这种情况，如对齐
    - 内部碎片容易量化，就是已分配块大小和有效载荷的差值
  - 外部碎片
    - 空闲空间合计起来足够满足一个分配请求，但是没有一个单独的空闲块足够大
    - 外部碎片难以量化且不可预测，因此分配器通常采用启发式策略来维持少量大空闲块而非大量小空闲块

### 9.9.5 实现问题

- 一个分配器要在吞吐率和利用率之间平衡，就要考虑以下问题
  - 空闲块组织：如何记录空闲块
  - 放置：如何选择一个合适的空闲块来放置一个新分配的块
  - 分割：在放置后，如何处理空闲块中的剩余部分
  - 合并：如何处理一个刚被释放的块
- 本届接下来的部分将更详细讨论这些问题

### 9.9.6 隐式空闲链表

- 分配器需要一些数据结构，来记录一些信息
  - 区别块边界
  - 区别已分配块和空闲块
  - 大多数分配器把这些信息嵌入块本身
- 图9-35是一个块的格式
  - 一个块由头部、有效载荷、可能的额外填充组成
- 图9-36将堆组织为一个连续的已分配块和空闲块的序列
  - 阴影为已分配块，没有阴影为空闲块
  - 一个方框为8字节大小
  - 头部标记为：块大小/是否已分配
  - 隐式空闲链表，因为分配器可以通过每个块头部的大小字段，遍历每个块，这样也就遍历了所有空闲块
  - 需要结束块
- 优缺点
  - 简单
  - 操作开销大，搜索空闲链表需要遍历整个链表
- 注意块对齐

### 9.9.7 放置已分配的块

- 当一个应用请求k字节的块时，分配器搜索空闲链表，找到一个足够大的空闲块，来放置请求块
- 放置策略
  - 首次适配
    - 从头开始搜索，选择第一个合适的
    - 大的空闲块保留在链表后面，而链表起始处有很多小的碎片
  - 下一次适配
    - 和首次试配相似，只不过不是从头开始，而是从上一次查询结束的地方开始
    - 搜索比首次适配快一些，因为上次在这个块匹配，这次很可能这次也能匹配（如果这个块比较大）
    - 内存利用率比首次适配低
  - 最佳适配
    - 检查每个空闲块，找到可以放置请求块的最小空闲块
    - 内存利用率比前两个策略高
    - 搜索时间长，需要搜索整个链表
    - 后面会提到更加精细复杂的分离式空闲链表组织

### 9.9.8 分割空闲块

- 分配器找到空闲块后，要做另一个策略决定，即如何分配空闲块
  - 用整个空闲块，简单，但是会有内部碎片
  - 分割成两部分，第一部分成为分配块，剩下的变成新的空闲块

### 9.9.9 获取额外的堆内存

- 分配器如果不能为请求块找到合适的空闲块，会有如下两种选择
  - 合并相邻的空闲块，来创造一个更大的空闲块（9.9.10）
  - 调用sbrk函数，向内核请求额外的堆内存

### 9.9.10 合并空闲块

- 相邻的空闲块引起假碎片，必须解决这个问题

- 合并的时机
  - 立即合并
    - 每次一个块被释放的时候，就合并所有的相邻块
    - 简单，且常数时间
    - 可能抖动，即反复合并，然后马上分割
    - 一般使用立即合并
  - 推迟合并
    - 例如，直到某个分配请求失败，再扫描整个堆，合并所有空闲块

### 9.9.11 带边界标记的合并

- 把想要释放的块称为当前块
- 合并当前块的下一个块
  - 非常简单且高效，因为当前块的头部指向下一个块的头部，通过当前块的大小和下一个块的空闲位，可判断是否可以合并，常数时间
- 合并前面的块
  - 只能搜索整个链表，线性时间复杂度
    - 能找到前面的块的尾部，但是没法知道前面的块的大小
- 边界标记
  - 解决上面提到的合并前一个块的问题，实现常数时间合并
  - 在块结尾出增加一个脚部，作为头部的副本
    - 现在找到上一个块尾部，就可以知道上一个块的大小了
  - 脚部的存在导致额外开销
- 边界标记的一种改进
  - 把前面块的空闲位放在当前块中多出来的低位
    - 因为对齐的原因，头部的块大小字段的后面几位通常0，可以用来保存前面块的空闲位
  - 这样，已分配的块就不需要脚部了
    - 如果发现前面块是已分配块，就不关心它的大小了，因此已分配块不用脚部

### 9.9.12 综合：实现一个简单的分配器

- ###

### 9.9.13 显式空闲链表

- 对于通用的分配器，隐式空闲链表不适合，因为分配时间与块的总数呈线性关系
- 图9-84展示了使用双向空闲链表的堆块的格式
  - 空闲块内嵌前驱和后驱指针
- 首次适配的分配时间，从块总数的线性时间减少到空闲块数量的线性时间
- 释放一个块的时间，取决于空闲链表中，块的排序策略
  - 后进先出，新释放的块放在链表的开始处
    - 释放一个块在常数时间内可以完成，直接添加到链表开始处
    - 如果使用了边界标记，合并在常数时间内完成
  - 地址顺序，链表中每个块的地址都小于它的后继地址
    - 释放一个块需要线性时间
    - 按照地址排序的首次适配比后进先出的首次适配有更高的内存利用率，接近最佳适配
- 显式链表的缺点
  - 空闲块必须足够大，以包含必要的指针、头部和可能的脚步，额外开销大

### 9.9.14 分离的空闲链表

- 单向空闲块链表的分配器，分配块的时间和块的数量线性相关，为了减少分配时间，采用分离存储的方法
  - 维护多个空闲链表，每个链表的块的大小大致相等
  - 这样，请求一个已知大小的块，就只需要在某个链表中搜索，这个链表的块大小都大致是请求块的大小
- 把所有的块划分为等价类（大小类）
  - {1}, {2}, {3, 4}, {5 ~ 8}, ..., {1025 ~ 2048}, ...

- 常用的分离存储方法
  - 简单分离存储
  - 分离适配

#### 9.9.14.1 简单分离存储

- 每个大小类的空闲链表包含大小相等的块
  - 例如，某个大小类定义为{17 ~ 23}，那么这个类的空闲链表全由大小为32的块组成
- 分配一个给定大小的块的操作
  - 检查相应的空闲链表
  - 如果链表非空，分配其中第一个块的全部
    - 不会分割空闲块，而是整个块分配
  - 如果链表为空，分配器向操作系统请求一个固定大小的新内存片，然后将这个片分成大小相等的块，串起来形成新的空闲链表
- 要释放一个块，只需要将这个块插入到相应的空闲链表前部
- 优缺点
  - 分配和释放块都是常数事件操作
  - 内存开销小
    - 块大小相等，不分割不合并，要记录的信息少
  - 内部和外部碎片多
    - 不会分割，容易造成内部碎片
    - 不会合并，容易造成外部碎片

#### 9.9.14.2 分离适配

- 每个空闲链表和一个大小类相关联，每个链表包含一些大小不同的块，快的大小是大小类的成员
- 分配一个块
  - 确定请求的大小类，并对适当的空闲链表做首次适配，找到合适的块
  - 如果找到一个，就分割它（如果有必要），并把剩余的部分插入到适当的空闲链表
  - 如果当前空闲链表中没有合适的块，就搜索更大的大小类的空闲链表，直到找到合适的块
  - 如果所有空闲链表都没有合适的块，请求额外的堆内存，生成新的链表
- 释放一个块
  - 执行合并，把结果放到相应的空闲链表

#### 9.9.14.3 伙伴系统

- 分离适配的特例，每个大小类都是2的幂，请求块向上舍入到最接近的2的幂
- 伙伴的地址
  - 给定块的大小，可以计算出它的伙伴（另外半块）的地址
  - 如，一个块的地址为xxxx0000，它的伙伴的地址为xxxx1000

- 优缺点
  - 快速搜索和合并
  - 内部碎片显著（向上舍入）

- 完全二叉树也可以实现伙伴系统

## 9.10 垃圾收集

- 程序员可能忘记释放某个块，导致它在程序的整个生命周期内都保持已分配状态，浪费
- 垃圾收集器
  - 一种动态内存分配器
  - 在一个支持垃圾收集的系统中，应用程序不用显式地释放堆块
- 本节讨论Mark&Sweep（标记&清除）算法

### 9.10.1 垃圾收集器的基本知识

- 垃圾收集器将内存视为一张有向可达图，如图9-49
  - 节点被分为一组根节点和一组堆节点
  - 每个堆节点对应于堆中的一个已分配块
  - 有向边p->q意味着块p中的某个位置指向块q中的某个位置
  - 根节点对应于不在堆中的位置，可能是寄存器、栈的变量，或者是虚拟内存中读写数据区域内的全局变量
- 不可达节点对应于垃圾，不能被再次使用，垃圾回收期维护可达图，定期释放不可达节点对应的堆

- 不同语言的垃圾收集器
  - Java和ML等语言的垃圾收集器，能维护可达图的精确表示，因此能回收所有垃圾
  - C和C++语言的垃圾收集器，每个可达块都被标记为可达，但是一些不可达节点也会被标记为可达，因此说它们是保守的垃圾收集器
- 将一个C程序的保守的收集器加入到已存在的malloc包中，如图9-50
  - 如果malloc找不到一个合适的空闲块，就调用垃圾收集器，希望能回收一些垃圾到空闲链表

### 9.10.2 Mark&Sweep垃圾收集器

- ###

### 9.10.3 C程序的保守Mark&Sweep

- ###

## 9.11 C程序中常见的与内存有关的错误

### 9.11.1 间接引用坏指针

- 进程的虚拟地址空间当中有洞，也就是区域之间的间隙，它们没有映射到任何有意义的数据

  - 区域的间隙和空闲块有什么区别？？？
  - 如果试图间接引用一个指向这些洞的指针，操作系统会以段异常中止程序

- 虚拟内存的某些区域是只读的，试图写这些区域，会触发保护异常，中止这个程序

- 间接引用坏指针的一个示例：scanf错误

  ```c
  scanf("%d", &val); /* 正确 */
  scanf("%d", val); /* 错误 */
  ```

  - scanf从stdin读一个整数到一个变量
  - 错误情况下，scanf把val解释为一个地址，并试图写一个字到这个位置
    - 好的情况下，这个地址非法，程序以异常终止
    - 坏的情况下，这个地址对应于虚拟内存的某个合法读/写区域，于是这块内存被覆盖

### 9.11.2 读未初始化的内存

- 不能假设堆内存已经被初始化为零，而是需要显式地把它们设置为零

### 9.11.3 允许栈缓冲区溢出

- 如果一个程序不检查输入串的大小，就写入栈的目标缓冲区，那么这个程序就有缓冲区溢出错误（3.10.3）
- gets复制任意长度的串到缓冲区，而fgets函数会限制输入串的大小

### 9.11.4 假设指针和它们指向的的对象是相同大小的

- 指针大小和它们指向的对象的大小不一定是相等的，因此用sizeof的时候要小心

### 9.11.5 造成错位错误

- ###

### 9.11.6 引用指针，而不是它们所指向的对象

- 注意操作符的优先级

### 9.11.7 误解指针运算

- 忘记了指针的算术操作是以它们指向的对象的大小为单位进行的，而这种大小的单位不一定是字节

- 例子

  ```c
  int *search(int *p, int val) {
      while (*p && *p != val)
          p += sizeof(int); /* should be p++ */
      return p;
  }
  ```

  这个函数本来是想遍历，现在却扫描了每4个

### 9.11.8 引用不存在的变量

- 引用了不再合法的本地变量，例如

  ```c
  int *stackref() {
      int val;
      return &val;
  }
  ```

  - 函数返回一个指针，指向栈里的一个局部变量，然后弹出这个局部变量的栈帧
  - p指向的内存地址是合法的，但这个地址已经不保存这个变量了，以后调用其它函数时，可能会保存其它函数的局部变量，这时分配某个值给*p，实际上修改了别的函数的局部变量

### 9.11.9 引用空闲堆块中的数据

- ###

### 9.11.10 引起内存泄漏

- 忘记释放已分配块

