# 第6章 存储器层次结构

- 之前对系统的研究中，依赖于一个简单的计算机系统
  - CPU执行指令
  - 存储器系统为CPU存放指令和数据
    - 注意区分存储器系统和寄存器，寄存器是在CPU内部的
    - 存储器系统是一个线性的字节数组
- 实际上存储器系统是一个层次结构
  - 需要的数据可能存在不同的存储器层中，这会导致指令需要经过不同的周期长度才能获取到数据（内存延迟）
- 局部性
- 一些存储技术
  - 高速缓存存储器
  - SRAM
  - DRAM
  - ROM
  - 旋转硬盘
  - 固态硬盘
- 存储器山

## 6.1 存储技术

### 6.1.1 随机访问存储器

- 随机访问存储器（RAM）分为静态（SRAM）和动态（DRAM）

#### 6.1.1.1 静态RAM

- SRAM将每个位存储在一个双稳态的存储器单元里
- 双稳态见图6-1
- 只要有电，就会永远保持它的值，就算有干扰，消除后也会恢复到稳定值

#### 6.1.1.2 动态RAM

- 将每个位存储为对一个电容的充电
- SRAM和DRAM的特性比较见图6-2

#### 6.1.1.3 传统的DRAM

- 一个例子，图6-3
  - d = 16个超单元，行r = 4，列c = 4，每个超单元有w = 8位
  - 两组引脚
    - 地址引脚2位
    - 数据引脚w = 8位
  - 内存控制器
    - 这个电路可以一次传送w为到每个DRAM芯片，或者一次从每个DRAM芯片传出w位
  - 现在要读出超单元(2, 1)的内容
    - 图6-4a
    - 图6-4b
- DRAM组织成二维阵列而非线性数组
  - 图6-3的例子，如果组织成线性数组，需要4位地址引脚，现在只需要2位
  - 缺点是要分两步发送地址，增加访问时间

#### 6.1.1.4 内存模块

- DRAM芯片封装在内存模块中，插到主板的扩展槽上
- 一个例子，图6-5
  - 访问主存地址A处的64位字
  - 内存控制器把A转换成一个超单元地址(i, j)，然后发送到内存模块
  - 内存模块把 i 和 j 广播到每个DRAM
  - 每个DRAM输出它的 (i, j) 超单元的8位内容
  - 模块中的电路合并这些内容成64位字，返回给内存控制器
- 多个内存模块聚合成主存，也就是说对主存的访问，实际上都是访问DRAM芯片

#### 6.1.1.5 增强的DRAM

###

#### 6.1.1.6 非易失性存储器

- 如果断电，RAM会丢失信息，是易失的
- 非易失性存储器ROM
  - 断电后仍能保存
  - 处于历史原因，它们被称为只读寄存器（ROM），虽然有些既可以写又可以读
- ROM按照可重编程的次数，和重编程所用机制来区分
  - 可编程ROM（PROM）只能编程一次
    - 每个存储器单元有一种熔丝，只能用高电流熔断一次
  - 可擦写可编程ROM（EPROM）
    - ###
  - 电子可擦除PROM（EEPROM）
    - ###
  - 闪存
    - 固态硬盘（SSD）基于闪存（6.1.3）
- 固件
  - ###

#### 6.1.1.7 访问主存

- 总线

  - 数据通过总线在处理器和DRAM主存之间来回
  - CPU和主存之间的数据传送都是通过一系列步骤完成的，这些步骤被称为总线事务
    - 读事务从主存传送数据到CPU
    - 写事务从CPU传送数据到主存
  - 总线能携带地址、数据和控制信号
    - 数据和地址信号可以共享同一组导线，也可以使用不同的
    - 两个以上的设备也能共享统一总线
    - 控制线携带的信号？？？

- 图6-6展示了一个实例计算机系统的配置

  - 主要部件

    - CPU芯片
    - 被称为I/O桥接器的芯片组（包括内存控制器）
      - 把系统总线的电子信号翻译成内存总线的电子信号
      - 把系统总线和内存总线连接到I/O总线？？？
    - 主存，由DRAM内存内存模块组成
    - 总线连接起来上述部件
      - 系统总线连接CPU和I/O桥接器
      - 内存总线连接I/O桥接器和内存

  - 当CPU执行如下加载操作时会发生什么

    ```x86arm
    movq A,%rax
    ```

    - 地址A的内容被加载到寄存器%rax中
    - CPU芯片上的总线接口电路在总线上发起读事务
      - 首先，CPU把地址A放到系统总线上，I/O桥把信号传递到内存总线，如图6-7a
      - 主存收到内存总线上的地址信号，从内存总线读地址，根据地址从DRAM读出数据（6.1.1.3，图6-3），并把数据写到内存总线，然后I/O桥把内存总线信号翻译成系统总线信号，如图6-7b
      - CPU收到系统总线上的数据，读出来并复制到寄存器%rax，如图6-7c

  - 当CPU执行如下存储操作时会发生什么

    ```x86arm
    movq %rax,A
    ```

    - 注意地址和数据的流向都是CPU->主存

### 6.1.2 磁盘

#### 6.1.2.1 磁盘构造

- 盘片
- 盘面
- 主轴
- 旋转速率
- 磁道
- 扇区
- 间隙
  - 标识扇区的格式化位
- 柱面
  - 所有半径相等的同心圆（磁道）

#### 6.1.2.2 磁盘容量

- 记录密度
  - 单位长度的段中可以放入的位数
- 磁道密度
  - 半径方向上，单位长度的段内的磁道数
- 面密度
  - 记录密度与磁道密度的乘积
- 多区记录
  - 外圈磁道的分区多于内圈磁道
  - 防止间隙太大

#### 6.1.2.3 磁盘操作

- 磁盘用读/写头来读写存储在磁性表面上的位

- 读/写头连接到传送臂一端，通过在半径方向上的移动，可以把读写头定位到任何磁道上，这个过程称为寻道

- 每个盘面都有一个读/写头，在任何时刻所有读/写头都位于同一个柱面上
- 读/写头离盘面很近，为了防止读/写头冲撞（撞到盘面上的灰尘），磁盘总是密封包装
- 磁盘以扇区大小的块来读写数据，对扇区的访问时间由三个部分组成
  - 寻道时间
    - 传动臂把读/写头定位到包含目标扇区的磁道上的耗时
    - 读取的时候，会先确定磁道
  - 旋转时间
    - 等待目标扇区的第一个位旋转到读/写头下的耗时
  - 传送时间
    - 读写改扇区内容的耗时

#### 6.1.2.4 逻辑磁盘块

- 磁盘构造复杂，有多个盘面，可能还有多区记录，因此有必要对用户隐藏这些细节，用户只知道有多少个块以及块号分别有哪些
  - 用户在发起读某个逻辑块号的请求时，磁盘控制器会把逻辑块号翻译成（盘面、磁道、扇区）
  - 接卸来的读取过程见6.1.2.3

#### 6.1.2.5 连接I/O设备

- 鼠标、键盘、磁盘这样的I/O设备，都是通过I/O总线，如PCI总线，连接到CPU和主存的
- 系统总线和内存总线都与CPU相关，而PCI这样的I/O总线设计成与底层CPU无关，PC和Mac都可以使用PCI总线
- ###

#### 6.1.2.6 访问磁盘

- 内存映射I/O
  - 地址空间有一块地址是为了与I/O设备通信而保留的
    - 也就是说，内存和I/O设备共享一个地址空间，当CPU访问内存时，可能访问到物理内存，也可能访问到I/O设备的内存
  - 每个这样的地址称为一个I/O端口

- 一个例子，图6-12，CPU发起磁盘读
  - 是物理内存和磁盘存储共同组成一个地址空间，还是物理内存和磁盘存储有部分重叠？？？
  - 中断，见8.1

### 6.1.3 固态硬盘

- 固态硬盘（SSD）是一种基于闪存的存储技术（6.1.1）

  - 很多时候可以代替传统的旋转磁盘

- 内部的一些结构

  - 闪存芯片
    - 替代旋转磁盘中的机械驱动器？？？
  - 闪存翻译层
    - 和旋转磁盘的机械驱动器一样，把请求的逻辑块翻译成对底层设备的访问

- 分层结构

  - 一个闪存有B个块，每个块有P个页
  - 读写都以页为单位进行

- SSD的一些特性见图6-14

  - 读比写要快

    - 读写以页为单位进行（按照后面的说法，是页还是块？？？），写一个页需要把该页所属的块都擦除，因此写要慢一些

    - 写一个已有数据的页，需要把这个页所属的整个块复制到一个未使用过的块

- SSD比起旋转磁盘的优点

  - 没有移动的部件，不像旋转磁盘那样要旋转，因此随机访问时间更短，能耗更低

- SSD的缺点

  - 反复写之后，闪存块会磨损
    - 平均磨损
  - 价格贵，因此存储容量更小

### 6.1.4 存储技术趋势

###

## 6.2 局部性

- 局部性的形式
  - 时间局部性
    - 被引用过一次的内存位置很可能在不远的将来再被多次引用
  - 空间局部性
    - 如果一个内存位置被引用了一次，那么程序很可能在不远的将来引用附近的一个位置
- 如何实现局部性
  - 高速缓存存储器（对主存的缓存，见6.4）
  - 利用主存作为磁盘块的缓存
  - 浏览器将最近被引用的文档存储到本地磁盘上

### 6.2.1 对程序数据引用的局部性

- 一个例子，一维数组，图6-17

  ```c
  int sumvec(int v[N]) {
      int i, sum = 0;
      for (i = 0; i < N; i++) 
          sum += v[i];
      return sum;
  }
  ```

  - sum有时间局部性，没有空间局部性
  - v有空间局部性，没有时间局部性

- 引用模式

  - sumvec这样顺序访问向量的每个元素的函数，具有步长为1的引用模式
  - 步长为k的引用模式
  - 步长为1的引用模式是空间局部性的重要来源，随着步长增加，空间局部性下降

- 另一个例子，二维数组，图6-18

  ```c
  iint sumarrayrows(int a[M][N]) {
      int i, j, sum = 0;
      for (i = 0; i < M; i++)
          for (j = 0; j < N; j++)
              sum += a[i][j];
      return sum;
  }
  ```

  - 这是步长为1的引用模式

- 稍作改动后空间局部性变差的例子，图6-19

  ```c
  int sumarraycols(int a[M][N]) {
      int i, j, sum = 0;
      /* 按列顺序扫描 */
      for (j = 0; j < N; j++)
          for (i = 0; i < M; i++)
              sum += a[i][j];
      return sum;
  }
  ```

  - 这是步长为N的引用模式

### 6.2.2 取指令的局部性

- 评价图6-17的例子的局部性
  - 循环内的指令是一条一条存储在连续的内存的，因此具有空间局部性
  - 循环体会被执行多次，因此具有时间局部性

### 6.2.3 局部性小结

- 在学习高速缓存存储器后，会介绍如何用高速缓存命中率来量化局部性

## 6.3 存储器层次结构

- 6.1节和6.2节分别描述了存储技术和计算机软件的属性
  - 存储技术：不同存储技术的差异，速度快的容量小
  - 计算机软件：好的程序具备良好的局部性
- 为了利用好上述这些属性，可以利用存储器层次结构（图6-21）
  - 也就是说，为了实现较好的局部性，可以用上一些速度更快的存储技术

### 6.3.1 存储器层次结构中的缓存

- 图6-22显示了两层相邻的存储器
  - 数据以块为传送单元，在两层之间来回复制
  - 低层有更多的块

#### 6.3.1.1 缓存命中

#### 6.3.1.2 缓存不命中

- 替换策略
  - 随机替换策略
  - 最近最少被使用（LRU）
  - ###

#### 6.3.1.3 缓存不命中的种类

- 冷不命中（强制性不命中）

  - 第k层缓存为空（冷缓存）时发生
  - 反复访问存储器一段时间后会缓存暖身

- 只要发生了不命中，就必须执行放置策略，确定把第k+1层中取出的块放到第k层的哪个块

  - 随机放置
    - 速度最快，但定位代价高

  - 第k+1层的某个块放到第k层的一个子集中
    - 例如，第k+1层的块i放在第k层的块 (i mod 4) 中

- 冲突不命中

  - 由上述限制性的放置策略引起
    - 例如，按以下顺序请求块0、8、0、8...则会一直不命中
    - 这是由于缓存太小引起的

- 容量不命中

  - 一个循环可能会反复访问一个数组的元素，这种块的集合被称为这个阶段的工作集
  - 当工作集大小超过缓存大小时，缓存会经历容量不命中

#### 6.3.1.4 缓存管理

- 把缓存划分成块，才能判定是否命中，并且进行处理

### 6.3.2 存储器层次结构概念小结

- 常用的一些缓存以及特性见图6-23

## 6.4 高速缓存存储器

- 早期的存储器层次结构只有三层
  - CPU寄存器
  - DRAM主存
  - 磁盘存储
- 后来因为CPU和主存的速度差距越来越大，在它们之间插入了SRAM高速缓存存储器，称为L1高速缓存
  - 现代存储器层次结构中，已经有L3甚至更多层，但这里还是假设只有L1

### 6.4.1 通用的高速缓存存储器组织结构

- 存储器地址m位，因此形成M = 2<sup>m</sup> 个地址
- 缓存的组织方式
  - S = 2<sup>s</sup> 组
  - 每组 E 个高速缓存行
  - 每行（缓存的一个块和一些附带信息）
    - 1个有效位
    - t个标记位，相当于行号
    - 大小为 B = 2<sup>b</sup> 的块 
- 缓存的结构
  - 可以用元组 (S, E, B, m) 表示
  - 缓存大小 C = S * E * B
- 缓存把地址按如下方式组织
  - t位标记
  - s位组索引
  - b位块偏移
- 当加载指令指示CPU从主存地址A读一个字时，CPU会把地址A发送到缓存，缓存如何知道自己是否包含地址A的那个字的副本
  - 先根据s位组索引，找到组
    - 一定有这个组
  - 再根据t位标记位，找到行
    - 对于映射到同一个组的块来说，需要通过标记位区分开，而属于不同组的块，标记位可以是相同的
      - 也就是说，一个块需要通过索引和标记位来唯一标识
    - 有可能没有这个行
    - 而且有效位设置了才说明这行有这个字
  - 最后根据b位块内偏移量，在缓存的这一行的块中，找到要的字

### 6.4.2 直接映射高速缓存

- 根据每个组的高速缓存行数E，高速缓存被分为不同的类
  - E = 1 的高速缓存被称为直接映射高速缓存
- 高速缓存判断一个请求是否命中，然后（从块中）抽取出被请求的字的过程，分为三步
  - 组选择
  - 行匹配
  - 字抽取

#### 6.4.2.1 直接映射高速缓存中的组选择

- 根据s个组索引位，找到对应的组

#### 6.4.2.2 直接映射高速缓存中的行匹配

- 每个组只有一行
- 只需要判断行标记是否匹配，而且有效位是否被设置

#### 6.4.2.3 直接映射高速缓存中的字选择

- 根据偏移量计算块内偏移

#### 6.4.2.4 直接映射高速缓存中不命中时的行替换

- 因为只有一行，所以只需要用新的行驱逐当前的行

#### 6.4.2.5 综合：运行中的直接映射高速缓存

- 假设有一个高速缓存，描述为 (S,E,B,m) = (4, 1, 2, 4)
  - 注意图中的块[0]、块[1]不是分别表示两个块，而是分别表示块的2个字节（块是2字节大小）

#### 6.4.2.6 直接映射高速缓存中的冲突不命中

- 冲突不命中见6.3.1.3

- 一个导致冲突不命中的例子

  ```c
  float dotprod(float x[8], float y[8]) {
      float sum = 0.0;
      int i;
      for (i = 0; i < 8; i++) 
          sum += x[i] * y[i];
      return sum;
  }
  ```

  - x和y具有良好的空间局部性
  - 现假设浮点数是4个字节，一个块是16字节；高速缓存由两个组组成；每个组16字节，缓存块足够大（可容纳4个浮点数）
  - 在上述两个有利的前提条件下，缓存命中率并不高
    - 第一次迭代引用x[0]，缓存不命中，导致x[0] ~ x[3]的块被加载到组0
    - 接下来引用y[0]，导致y[0] ~ y[3] 的块被加载到组[0]，覆盖掉之前的x[0] ~ x[3]
    - 第二次迭代引用x[1]...
    - 这样的冲突不命中，称为在x和y的引用之间抖动

- 修正抖动问题的策略

  - 在每个数组的结尾放B字节的填充

  - 例如上述例子中，把x定义为float [12]

    见书上图，x[0] ~ x[3] 不会映射到同一组

- 为什么高速缓存用中间的位来作为主索引
  - 如果用高位做索引，那么一些连续的内存块会映射到同一组（也就是同一行，直接映射高速缓存每组只有一行）
  - 在遍历数组的时候，可能需要遍历头几个连续块，如果按照高位做索引，那么可能会出现数组遍历时经常缓存不命中（缓存可能放不下这几个块）

### 6.4.3 组相联高速缓存

- 直接映射高速缓存中，冲突不命中造成的原因是每组只有一个行（E = 1），因此组相联高速缓存放宽这条限制，使得 1 < E < C/B（C = S * E * B）
- 如果是E = C/B，此时S = 1（只有一组），这种情况见6.4.4

#### 6.4.3.1 组相联高速缓存中的组选择

- 和直接映射高速缓存一样，通过组索引位标识组

#### 6.4.3.2 组相联高速缓存中的行匹配和字选择

- 每个组都可以看成一个相联存储器
- 相联存储器是一个kv对数组，key是有效位和标记位，value是块的内容
  - 对比直接映射高速缓存，找到组再看有效位就可以了

#### 6.4.3.3 组相联高速缓存中不命中时的行替换

- 有空行直接替换空行
- 一些替换策略如LRU、LFU等等

### 6.4.4 全相联高速缓存

- 只有一个组，包含了所有行

#### 6.4.4.1 全相联高速缓存中的组选择

- 地址中没有组索引位，因为只有一个组

#### 6.4.4.2 全相联高速缓存中的行匹配和字选择

- 和组相联高速缓存大致一样
- 一般并行搜索行，因为行比较多
- 适用于做小的高速缓存（行比较少），如虚拟内存系统中的翻译备用缓冲器（TLB），见9.6.2节

### 6.4.5 有关写的问题

- 读操作非常简单
  - 查找命中则立即返回
  - 否则从下一层存储读
- 写的情况更复杂，需要解决一些问题
  - 在缓存中更新后，如何同步到低一层的存储，一些同步策略
    - 直写
      - 立即把更新的高速缓存块写回到低一层存储
      - 简单
      - 每次都会引起总线流量
    - 写回
      - 只有当替换算法要驱逐更新过的块时，才写到低一层的存储
      - 减少总线流量（若某个块在被替换之前更新好多次，则只需要被替换时写回一次，不用每次更新都写回）
      - 每个高速缓存行（块）需要额外维护一个修改位，表明这个块是否修改过
  - 如何处理写不命中（要写的块不在缓存中）
    - 写分配
      - 加载低一层的块到高速缓存中，然后更新这个块
      - 利用了写的局部性（很可能短时间内再写这个块，所以先加载到缓存，下次就可以直接写缓存）
      - 每次不命中都需要加载一次，总线流量大
    - 非写分配
      - 避开高速缓存，直接写低一层
    - 直写高速缓存通常是非写分配（写回次数多，容易写不命中），写回高速缓存通常是写分配

### 6.4.6 一个真实的高速缓存层次结构的剖析

- 之前假设高速缓存只保存数据（d-cache），实际上也会保存指令（i-cache）
- 现代处理器通常包括独立的i-cache和d-cache，使得机器能够同时读一个指令字和一个数据字
- 图6-38，Intel Core i7处理器的高速缓存层次结构
  - CPU四个核
  - 每个核有自己的L1 i-cache、L1 d-cache和L2统一的高速缓存
  - 所有核共享L3统一的高速缓存
  - 所有的SRAM高度缓存存储器都在CPU芯片上

### 6.4.7 高速缓存参数的性能影响

###

## 6.5 编写高速缓存友好的代码

- 高速缓存友好意味着更低的命中率
- 确保代码高速缓存友好的基本方法
  - 优先让最常见的情况运行得快
  - 尽量减少每个循环内部的缓存不命中频率
- 从缓存命中率的角度，考虑6.2中的两个例子（图6-17和图6-18）
  - 现假设块大小为4个元素
  - 如果步长为1，那么命中率大概为75%（v[0]、v[3]、v[7]...不命中），这是能做到的最好情况，因此这两个例子都是高速缓存友好的

## 6.6 综合：高速缓存对程序性能的影响

### 6.6.1 存储器山

- 读吞吐量（读带宽）
  - 一个程序从存储系统中读数据的速率
- 图6-40是测量吞吐量的函数
  - 为了提高循环的并行性，4 * 4展开（5.9）
  - 要先进行缓存暖身，再开始测试吞吐量
  - size是要读的字节数
    - 值越小，工作集越小，时间局部性越好（更有可能短时间内又访问这个元素）
  - stride是每次读元素的间隔
    - 比如stride为8，则应该读元素的下标为0、1、2、3、8、9、10、11...
    - 值越小，空间局部性越好（更有可能访问附近的元素）
  - elems是要读的元素个数
  - 返回值是吞吐量，单位为MB/s
- 图6-41是存储器山
  - 是一个二维函数图像
    - 两个横轴分别是size（大小轴）和stride（步长轴）
    - 各级缓存和块大小都已标明
  - 垂直于大小轴的四条山脊，分别对应于工作集完全在L1高速缓存、L2高速缓存、L3高速缓存和主存的情况
    - 也就是说，工作集大小和缓存大小相等
  - L2、L3和主存山脊上，随着步长增加，空间局部性下降，因此吞吐量变小
  - 山脊的最高点和最低点差别很大，因此即使工作集非常大（时间局部性很差），也要留意空间局部性
  - 垂直于步长轴的一条山脊，对应于步长为1的情况，此时即使工作集比较大，性能依然较好
    - 这是因为硬件预取机制，系统会自动识别步长为1的引用模式，试图在一些块被访问前，取到高速缓存中

### 6.6.2 重新排列循环以提高空间局部性

- 假设现在有一对n * n矩阵相乘
  - 做如下 前提假设
    - 每个数组都是double类型的n * n数组，sizeof(double) == 8
    - 只有一个高速缓存，块大小为32字节
    - n很大，矩阵的一行没法完全装进高速缓存
    - 所有局部变量都存储到寄存器，因此对局部变量的引用不用加载或存储指令
  - 6个在功能上等价的版本，见图6-44
    - 分成3个等价类，分类依据是内循环中访问的矩阵对
    - 图6-44a和图6-44b是类AB，以此为例计算未命中总次数
      - 每次迭代以步长为1扫描A的一行，以步长为n扫描B的一列
      - 每个块大小为4个8字节
      - 因此，A的不命中率是0.25，B的不命中率是1
      - 所以每次迭代会有1.25次不命中
    - 同理，算出来的结果见图6-45

### 6.6.3 在程序中利用局部性

- 推荐采用下列技术来编写出更有效的程序
  - 注意力在内循环
  - 尽量以步长为1的方式来读数据
  - 一旦从存储器读入一个数据，尽可能多地使用它，增强时间局部性